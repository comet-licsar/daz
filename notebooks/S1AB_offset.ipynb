{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y, y_pred, ddof=2):\n",
    "    return np.sqrt( np.sum(np.square(y - y_pred)) / (len(y)-ddof) )\n",
    "\n",
    "\n",
    "def model_filter(A, y, limrms=3, iters=2):\n",
    "    '''\n",
    "    limrms is 'how many RMSEs should be used to remove outliers'\n",
    "    '''\n",
    "    model = np.linalg.lstsq(A,y, rcond=False)[0]\n",
    "    ddof = A.shape[1]\n",
    "    y_pred = np.sum(A*model,axis=1)\n",
    "    rmse = get_rmse(y, y_pred, ddof=ddof)\n",
    "    for i in range(iters):\n",
    "        count = len(y)\n",
    "        # reducing dataset\n",
    "        sel = np.abs(y_pred - y)<limrms*rmse\n",
    "        y = y[sel]\n",
    "        if len(y)==count:\n",
    "            break\n",
    "        A = A[sel]\n",
    "        # second iteration (only)\n",
    "        model = np.linalg.lstsq(A,y, rcond=False)[0]\n",
    "        y_pred = np.sum(A*model,axis=1)\n",
    "        rmse = get_rmse(y, y_pred, ddof=ddof)\n",
    "    stderr = np.sqrt(rmse**2/len(y))\n",
    "    return model, stderr\n",
    "\n",
    "\n",
    "def get_s1b_offset(epd, fpd, col = 'daz_mm_notide_noiono', fix_pod_offset = True, rmsiter = 2,\n",
    "                   split_by_pod = True, fit_offset = False, return_model = False, startfromnoiono = True, mincount = 80 ):\n",
    "    '''\n",
    "    epd = selected esd pandas dataframe\n",
    "    fpd - selected frame pd df\n",
    "    '''\n",
    "    if fit_offset and fix_pod_offset:\n",
    "        print('you do not want to do both..')\n",
    "        return False\n",
    "    try:\n",
    "        epd = epd.set_index(epd.epochdate)\n",
    "        epd = epd.sort_index()\n",
    "    except:\n",
    "        print('')\n",
    "    if startfromnoiono:\n",
    "        stdate=pd.Timestamp('2016-07-30').date()\n",
    "        epd = epd[epd.index>stdate]\n",
    "        if epd.empty:\n",
    "            return np.nan\n",
    "    dazes = epd[col].copy() #.values\n",
    "    poddate = pd.Timestamp('2020-07-30')\n",
    "    if fix_pod_offset:\n",
    "        dazes[dazes.index<poddate]-=39\n",
    "    epochdates = epd.index.values\n",
    "    years = epd.years_since_beginning.values\n",
    "    dazes = dazes.values\n",
    "    masterdate = pd.Timestamp(fpd.master.values[0])\n",
    "    mastersat = fpd.s1AorB.values[0]\n",
    "    isB = flag_s1b(epochdates, masterdate, mastersat)\n",
    "    if not split_by_pod:\n",
    "        if fit_offset:\n",
    "            is_pre = (epochdates<poddate).astype(np.int0)\n",
    "            A = np.vstack((years,np.ones_like(years),isB, is_pre)).T\n",
    "            model, stderr = model_filter(A, dazes, iters=rmsiter)\n",
    "            #model = np.linalg.lstsq(A,dazes, rcond=False)[0]\n",
    "            cAB = model[2]\n",
    "            pod_offset = model[3]\n",
    "            if not return_model:\n",
    "                return pod_offset\n",
    "        else:\n",
    "            # now, we do d = A m, where A is of dt, 1, isB:\n",
    "            A = np.vstack((years,np.ones_like(years),isB)).T\n",
    "            model, stderr = model_filter(A, dazes, iters=rmsiter)\n",
    "            #model = np.linalg.lstsq(A,dazes, rcond=False)[0]\n",
    "    else:\n",
    "        # now, we do d = A m, where A is of dt, 1, isB_pre, isB_post:\n",
    "        isB_pre = (epochdates<poddate).astype(np.int0)*isB\n",
    "        isB_post = (epochdates>=poddate).astype(np.int0)*isB\n",
    "        minepochs = 10\n",
    "        if (np.sum(isB_pre) < minepochs) or (np.sum(isB_post) < minepochs):\n",
    "            return np.nan\n",
    "        A = np.vstack((years,np.ones_like(years),isB_pre, isB_post)).T\n",
    "        model, stderr = model_filter(A, dazes, iters=rmsiter)\n",
    "        #model = np.linalg.lstsq(A,dazes, rcond=False)[0]\n",
    "        cAB_pre = model[2]\n",
    "        cAB_post = model[3]\n",
    "        cdiff = cAB_post - cAB_pre\n",
    "        if not return_model:\n",
    "            return cdiff\n",
    "    if not return_model:\n",
    "        #v = model[0]\n",
    "        #c = model[1]\n",
    "        c_AB = model[2]\n",
    "        if c_AB == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return c_AB\n",
    "    else:\n",
    "        #get rmse -> stderr, return it\n",
    "        return model, stderr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def flag_s1b(epochdates, masterdate, mastersat = 'A'):\n",
    "    if mastersat == 'B':\n",
    "        masterdate = masterdate + pd.Timedelta('6 days')\n",
    "    isB = []\n",
    "    for epoch in epochdates:\n",
    "        # ok, give +- 1 day tolerance due to midnight issue\n",
    "        if np.abs(np.mod((epoch - masterdate.date()).days, 12)) <= 1:\n",
    "            isB.append(0)\n",
    "        else:\n",
    "            isB.append(1)\n",
    "    isB = np.array(isB)\n",
    "    return isB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "poddate = pd.Timestamp('2020-07-30')\n",
    "esds = pd.read_csv('esds_202205/esds.csv')\n",
    "#framess='/gws/nopw/j04/nceo_geohazards_vol1/projects/LiCS/proc/current/esds_2022/backup/s1aorb.csv'\n",
    "#framess=pd.read_csv(framess)\n",
    "\n",
    "esdir = '/gws/nopw/j04/nceo_geohazards_vol1/projects/LiCS/proc/current/esds_and_ranges_2020data'\n",
    "inframesfile = os.path.join(esdir,'esds2021_frames_take4_withrg.csv')\n",
    "\n",
    "framess = pd.read_csv(inframesfile)\n",
    "#framespd \n",
    "\n",
    "mdates=[]\n",
    "for frame in framess['frame']:\n",
    "    mdate = fc.get_master(frame, asdate=True)\n",
    "    mdates.append(mdate)\n",
    "\n",
    "framess['master']=mdates\n",
    "framess['opass'] = framess['frame'].str[3]\n",
    "framespd = framess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extend the dataset:\n",
    "polyid = lq.sqlout2list(lq.get_frame_polyid(frame))\n",
    "dazes = []\n",
    "for epoch in b.epoch:\n",
    "    dbdaz = lq.get_daz(polyid[0], epoch)\n",
    "    dazes.append(dbdaz)\n",
    "\n",
    "# or in full:\n",
    "    \n",
    "minBs = 25\n",
    "minall = 75\n",
    "poddate = pd.Timestamp('2020-07-30')\n",
    "offsets = []\n",
    "podoffs = []\n",
    "counts = []\n",
    "frames = []\n",
    "for i,r in framess.iterrows():\n",
    "    frame=r['frame']\n",
    "    mastersat=r['s1AorB']\n",
    "    masterdate=r['master']\n",
    "    if not masterdate:\n",
    "        continue\n",
    "    # get the dazes:\n",
    "    try:\n",
    "        polyid = lq.sqlout2list(lq.get_frame_polyid(frame))[0]\n",
    "        daztb = fc.lq.do_pd_query('select * from esd where polyid={};'.format(polyid))\n",
    "        daztb = daztb.set_index(daztb.epoch).sort_index()\n",
    "        dazes = (daztb['daz'])*14000\n",
    "    except:\n",
    "        continue\n",
    "    if dazes.empty:\n",
    "        continue\n",
    "    stdate=pd.Timestamp('2016-07-30').date()\n",
    "    dazes = dazes[dazes.index>stdate]\n",
    "    if dazes.count()<minall:\n",
    "        continue\n",
    "    epochdates = dazes.index.values\n",
    "    tdif = epochdates - epochdates[0]\n",
    "    years = pd.DataFrame(tdif)[0].apply(lambda x: float(x.days)/365.25).values\n",
    "    isB = flag_s1b(epochdates, masterdate, mastersat)\n",
    "    if np.sum(isB)< minBs:\n",
    "        continue\n",
    "    is_pre = (epochdates<=poddate.date()).astype(np.int0)\n",
    "    A = np.vstack((years,np.ones_like(years),isB, is_pre)).T\n",
    "    model = np.linalg.lstsq(A,dazes, rcond=False)[0]\n",
    "    cAB = model[2]\n",
    "    podoff = model[3]\n",
    "    offsets.append(cAB)\n",
    "    counts.append(len(epochdates))\n",
    "    podoffs.append(podoff)\n",
    "    frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "vels2 = []\n",
    "offs2 = []\n",
    "podoffs = []\n",
    "stderrs = []\n",
    "for frame in framespd['frame']:\n",
    "    #print(frame)\n",
    "    fpd = framespd[framespd['frame'] == frame]\n",
    "    epd = esds[esds['frame'] == frame]\n",
    "    #offsetdiff = get_s1b_offset(epd, fpd)\n",
    "    modell, stderr = get_s1b_offset(epd, fpd, split_by_pod = False, fit_offset = True, fix_pod_offset = False, return_model = True)\n",
    "    if type(modell) == type(np.nan):\n",
    "        modell = [np.nan, np.nan, np.nan, np.nan]\n",
    "        stderr = np.nan\n",
    "    vels2.append(modell[0])\n",
    "    offs2.append(modell[2])\n",
    "    podoffs.append(modell[3])\n",
    "    stderrs.append(stderr)\n",
    "\n",
    "#print(offsets)\n",
    "#framespd['s1ab_offset_mm_prepost'] = offsetdiffs\n",
    "framespd['s1ab_offset_mm5'] = offs2\n",
    "framespd['vel5'] = vels2\n",
    "framespd['podoff5'] = podoffs\n",
    "framespd['stderr5'] = stderrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "framespd = framespd_selection.copy(deep=True)\n",
    "#framespd_selection = framespd.copy(deep=True)\n",
    "framespd = framespd[np.abs(framespd.vel5)<80]\n",
    "framespd = framespd[np.abs(framespd.podoff5)<110]\n",
    "framespd = framespd[np.abs(framespd.stderr5)<7]\n",
    "\n",
    "#framespd = framespd[framespd.podoff5<75]\n",
    "framespd=framespd[framespd.s1ab_offset_mm5>-50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist=framespd[framespd['opass']=='A'].podoff5.rename('ascending frames')*-1\n",
    "dist2=framespd[framespd['opass']=='D'].podoff5.rename('descending frames')*-1\n",
    "dist3=framespd.podoff5.rename('all frames')*-1\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "from palettable.colorbrewer.qualitative import Set2_7\n",
    "colors = Set2_7.mpl_colors\n",
    "\n",
    "params = {\n",
    "   'axes.labelsize': 8,\n",
    "   'font.size': 9,\n",
    "   'legend.fontsize': 8,\n",
    "   'figure.dpi' : 200,\n",
    "   #'xtick.labelsize': 10,\n",
    "   #'ytick.labelsize': 10,\n",
    "   #'text.usetex': False,\n",
    "   'figure.figsize': [3, 4]\n",
    "   # 'figure.figsize': [6, 4]\n",
    "   }\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#fig = plt.figure(figsize=(8,4), dpi=100)\n",
    "#ax.set_xlim(-100,100)\n",
    "bins1 = 12\n",
    "bins = bins1*2\n",
    "ax = dist.plot.hist(density=False, legend=True, color=colors[2], histtype='stepfilled',\n",
    "                ax=ax, bins=bins1, grid=True, alpha=0.5, edgecolor='k', \n",
    "                label='ascending frames')\n",
    "ax = dist2.plot.hist(density=False, legend=True, color=colors[4], histtype='stepfilled',\n",
    "                ax=ax, bins=bins1, grid=True, alpha=0.5, edgecolor='k',\n",
    "                label='descending frames')\n",
    "#dist3.plot.hist(density=True, legend=True,\n",
    "#                ax=ax, bins=60, grid=True, edgecolor='k', alpha=0.05, label='bagr')\n",
    "ax = dist3.plot.hist(density=False, legend=True, color=colors[4], histtype='step',\n",
    "                ax=ax, bins=bins, grid=True, alpha=0.85, edgecolor='red',linewidth=2,\n",
    "                label='all frames')\n",
    "\n",
    "               #title='Density histogram of $\\Delta(\\sigma_{post}-\\sigma_{pre})$', \n",
    "\n",
    "median_both = dist3.median()\n",
    "mean_both = dist3.mean()\n",
    "print('median values are:')\n",
    "print(dist.median())\n",
    "print(dist2.median())\n",
    "print(dist3.median())\n",
    "\n",
    "print('mean values are:')\n",
    "print(dist.mean())\n",
    "print(dist2.mean())\n",
    "print(dist3.mean())\n",
    "\n",
    "print('count:')\n",
    "print(dist3.count())\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlim(-120,80)\n",
    "ax.set_xlim(-100,100)\n",
    "#ax.set_ylim(0,0.4)\n",
    "#ax.set_title(\"Estimates of $\\Delta a$ offset due to POD change\")\n",
    "ax.set_title(\"$\\Delta a$ offset due to orbits change\")\n",
    "ax.grid(True)\n",
    "\n",
    "stderr_median=np.sqrt(dist3.var()/dist3.count())*2*1.253\n",
    "ax.axvline(median_both, color='k', linewidth=1, alpha = 0.7, linestyle='dashed', label='$\\overline{\\delta \\Delta a}$ ='+str(int(np.round(median_both)))+'$\\pm$'+str(np.round(stderr_median,1))+' mm')\n",
    "#ax.axvline(mean_both, color='k', linewidth=1, alpha = 0.7, linestyle='dashed')\n",
    "ax.set_ylim(0,90)\n",
    "min_ylim, max_ylim = ax.get_ylim()\n",
    "#ax.text(median_both+2, max_ylim*0.939, '$\\overline{\\delta \\Delta a}$',\n",
    "#        fontsize=11)\n",
    "#ax.text(median_both-14, max_ylim*0.939, '$\\overline{\\delta \\Delta a}$',\n",
    "#        fontsize=11)\n",
    "#ax.axvline(mean_both, color='k', linewidth=1, alpha = 0.7, linestyle='dashed')\n",
    "#ax.text(mean_both, max_ylim*0.95, ' $\\mu_{\\Delta,post}=$'+'{:.2f} mm'.format(mean_both),\n",
    "#        fontsize=9)\n",
    "\n",
    "#the daz_ARP = -39 mm\n",
    "ax.axvline(-39, color='b', linewidth=1, alpha = 0.7, label='$\\Delta a_{ARP}$ = -39 mm')\n",
    "#ax.text(-39+2, max_ylim*0.945, '$daz_{ARP}$ = -39 mm', color='b', fontsize=11)\n",
    "#ax.text(-39+1, max_ylim*0.941, '$\\Delta a_{ARP}$', color='b', fontsize=11)\n",
    "#ax.legend(facecolor='white', framealpha=1, loc='lower left')\n",
    "legend = ax.legend(frameon = 1, loc='upper right')\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "frame.set_linewidth(0)\n",
    "ax.set_xlabel('mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-champion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
